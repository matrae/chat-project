Towards animal-friendly machines

Abstract: Semi-autonomous machines, autonomous machines and robots inhabit closed, semi-closed and open environments. There they encounter domestic animals, farm animals, working animals and/or wild animals. These animals could be disturbed, displaced, injured or killed. Within the context of machine ethics, the School of Business FHNW developed several design studies and prototypes for animal-friendly machines, which can be understood as moral machines in the spirit of this discipline. They were each linked with an annotated decision tree containing the ethical assumptions or justifications for interactions with animals. Annotated decision trees are seen as an important basis in developing moral machines. They are not without problems and contradictions, but they do guarantee well-founded, secure actions that are repeated at a certain level. This article documents completed and current projects, compares their relative risks and benefits, and makes proposals for future developments in machine ethics. The findings in this article and proposals for the future hope to systemically promote animal well-being and prevent animal suffering in encounters between machines and animals.

Introduction

In closed, semi-closed and open environments, in households, gardens and parks, on business sites, in agricultural settings and in the open country, vehicles, complex machines, and more and more also remote-controlled, semi-autonomous and autonomous robots encounter domestic animals, farm animals, working animals or wild animals. Often, these encounters lead animals, being sensitive creatures and capable of suffering, to be disturbed, irritated and scared, or even injured and killed. A wellknown example is the fawn, which does not jump out of the field when the combine harvester approaches, but is paralyzed and curls up, only to be killed by the machine. Solution concepts are being developed in the context of human-machine interaction, animal-machine interaction, and machine ethics. These areas of research are located between artificial intelligence (AI), computer science, design, psychology, and philosophy. So-called moral machines – i.e. machines that will make the right decisions and behave correctly in a moral sense in situations with moral implications and that are subject and result of machine ethics – are interesting not only for increasing the well-being of humans, but also for keeping animals from harm. The issue is to develop customized machines that respond faster and better to human input, are capable of compensating for human deficits and take over more and more tasks. In that respect they have to possess social intelligence, or even moral skills. At the very least, they have to be able to recognize higher-developed animals, stop for them, shoo and chase them away; they also have to be able to recognize and assess consequences for humans, and sometimes decide against animal well-being. Within the context of machine ethics, several design studies and prototypes of animal-friendly machines have been developed at the School of Business FHNW. So far, decision trees have been rarely used in machine ethics [1, 2]. LADYBIRD was conceived in 2014 and implemented as a prototype in 2017. One of the foundations was an annotated decision tree, containing moral assumptions and justifications. ROBOCAR, a car that brakes for certain animal species, was also conceived in 2014 and presented as a model in 2016. Another concept includes a camera drone capable of taking photos of fauna and flora while being data protection-friendly as well as animal-friendly, or in other words considering the best interest of humans and animals. Also in this case, an annotated decision tree was created. The present article documents the aforementioned projects, their relative risks and benefits and makes proposals for future developments in machine ethics. The findings and proposals for the future hope to systemically promote animal well-being and prevent animal suffering in encounters between machines and animals.

Disciplines involved

Below disciplines of relevance in this context are introduced. This article concentrates mainly on machine ethics, but other aspects challenging other disciplines are referred to as well. Human-computer interaction, humanmachine interaction, robotics and artificial intelligence are considered already known. Animal-machine interaction is the interaction between animal and machine via an interface. The discipline with this name mentioned in the article “Considerations about the Relationship between Animal and Machine Ethics” [3] and explained in more depth in [4] deals with design, evaluation and implementation of machines in interaction with animals. Approaches towards a more specialized animal-computer interaction already exist in the Anglo-American language zone [5]. The object of machine ethics is the morality of machines, especially of autonomous and semi-autonomous systems such as software agents, certain robots, certain drones, computers in automated trading, and self-driving cars [6–8]. The discipline can be classified within information and technology ethics or considered an equivalent of human ethics, with a focus not on natural, but on artificial moral agents. The term of machine morality can be used similarly to the term of artificial intelligence (in this case, the object is meant, not the discipline). Machine ethics can be directed towards humans or towards animals. Animal ethics analyzes the duties of humans to animals as well as animal rights and values. There have been many controversial debates over time [9–12]. Animal ethics also works on the relationship between animals and (semi-)autonomous intelligent systems, such as agents and certain robots [3, 4]. This article is not only about animal ethics, but also about animal welfare.

Machines and animals

Below, possible encounters between semi-autonomous and autonomous machines or robots and animals in households, farming, and on open land are outlined briefly. While domestic, farm, working and wild animals are taken into account, laboratory animals can be considered a speciality not relevant to this discussion. Domestic animals come into contact with robot vacuum cleaners indoors and with robot mowers outdoors. They can also come into contact with robotic toys or entertainment robots, for instance robotic dogs. Increasingly, service robots (e.g. companion robots, information robots, transport robots and nursing robots) are present in houses and apartments, and this affects the animals living there. Automatic feeding stations are in use, for instance for domestic cats left on their own for a few days. Different interactions between systems and working and farm animals are possible, e.g., between cows and milking machines or robots, and between livestock and several components of cattle sheds, even if the latter are not very complex. Experiments with virtual fencing for farm animals are in progress, in which the animals wear high-tech collars or headpieces that will keep them from escaping [13]. Wild animals (as well as farm or working animals) can collide with harvesting or other farming robots [14] when moving in fields and meadows. In 2017 the media hyped a scarecrow-robot in the form of a wolf [15]. A lot of different animal robots are being developed to take over functions in flocks and herds, or “duties” of animals as social beings or interacting organisms [16]. Robots investigate the animal groups, influence them, try to steer and direct them, and make them behave in a certain way [17]. Robots that observe wild animals (as well as farm animals) and control them, and in case of emergency nurse and feed them, or put them down and kill them if required, are a vision for the future. Robots such as remote-controlled drones and remote-controlled animallike robots have been used for years for observing, photographing and filming animals. Now, semi-autonomous and autonomous robots enter the scene.

Annotated decision trees

Annotated decision trees are a way to design and implement moral machines. The nodes indicate what is to be observed and examined. Depending on the result, the system makes a decision. Moral assumptions and reasons are given for each node. So it is not just any decision tree – the annotations make it possible to specifically develop moral machines. The central components of an annotated decision tree are listed below [18]. At the edge of the decision tree, the class or type of machine is specified as a kind of header, and the target of the moral machine is described in a few words [18]. The starter symbol – a rounded or standard rectangle – briefly and precisely designates the task. Multiple tasks would require multiple decision trees. Behind the task and linked with an arrow element follows the root node with the first question. A rhombus is proposed as the symbol for the root node. Two branches (also in the form of arrows) branch off the root node towards two internal nodes or to one (but no more than one) decision. The branches are marked with “Yes” or “No” accordingly. The internal nodes are furnished with more questions for review [18]. They go out to more branches, to more nodes, or to the final decisions at the end. Root nodes and internal nodes are annotated as far as possible and necessary. This should be done in the comment mode to make sure the annotation is unambiguously linked to the question or the questions. Annotations are made from the perspective of morality (obligatory), economic efficiency, operational safety and so on. They can be numbered and ranked by priority. The endpoints – symbolized usually by rectangles – give decisions that can be implemented by the machine. They can be demarcated clearly and be described unambiguously, and they can lead to a plethora of alternatives.

The drone study

A drone is an unmanned aerial vehicle (UAV), remotecontrolled by humans, or operated by a computer, which makes it semi-autonomous or autonomous. Distinctions are made between drones meant for military, political, scientific, economic or journalistic, as well as private or personal, use [2]. Drones operate as single machines connected only to a more or less mobile control unit, or they are part of a more complex system with a ground station. Drones used for private or business purposes are steered by means of a smartphone or remote control. Often they have a camera for still or moving images [2]. With its help, and in conjunction with the display, they can be flown quite safely outside of the range of vision (unlike classic model planes). If the cameras are used to capture professional photos for purposes of the media or sciences, the aircrafts are also called camera or film drones. They are furnished with batteries or accumulators, modern electromotor and electronic components, sometimes with a stabilizing system, WiFi components and a GPS module, then the route to be flown can be defined via a map. The quadcopter with its four rotors is widely used. So far, annotated decision trees have not been used for camera drones available on the market [2]. UAV are already quite complex in their functions and duties. Their main purpose is flying, but flying is also a means to an end. Several tasks can be completed, ranging from surveillance to reporting to transport. For the following case it is assumed that a semi-autonomous drone shall take photos of fauna and flora. Humans are not relevant as motifs for factual reasons and they shall be protected in their informational autonomy. The modelling was presented in 2015 [2]. It starts with the activity of flying. Then the drone checks whether there is an object on the ground. If this is so, and this object is a human, the recording function will not be activated in order to respect the human’s privacy rights and rights in the human’s own image. If the object is an animal, the drone shall proceed according to species. Collisions with birds shall be avoided, and shy animals shall be left in peace. The latter will be photographed or filmed from long distances only. To give an example: The annotations at “Is it a bird?” (to be verified by cameras and sensors) are “MA2/BA1: Birds shall not be injured by the drone”, with that they refer to both the animal well-being and operational safety (see Figure 1). Recording rare animal species is done from different heights; the effort is worth it for economic reasons. This does not apply to items in this context, this means the same assumption will be negated in the decision tree. If the machine doesn’t recognize an animal, it will consider several other potential facts. The camera drone has not yet been implemented at the School of Business FHNW.

The ROBOCAR design study

More and more advanced driver assistance systems (ADAS) are built into cars. Some of them help the driver, inform and provide support. Others turn the machine, controlled by the driver, into a semi-autonomous machine that temporarily and partly functions independently of the driver. Recognition of traffic signs, braking, emergency braking and lane changing assistants, intelligent speed adaptors, parking assistants and autopilots are examples of ADAS. Highly and full automated and autonomous systems like self-driving cars are no longer science fiction. In recent years, prototypes like the Google or the Uber car as well as scientific and commercial projects [19, 20] have been developed. SmartShuttle, a small, autonomous bus, is on the road in Sion, Switzerland. In the long-term, highly and fully automated or autonomous machines and their corresponding systems will be independent of humans in their decisions, as well as in their movements and activities. Of course, the rules are predefined in the beginning, but these systems are capable of learning, also through their own observations and capable of prioritizing and adjusting rules. ADAS capable of making decisions relating to animals can be developed [4, 18, 21, 22]. There is a need for them illustrated by many signs in different countries, warning for instance of toad migration, hedgehog populations, or deer passing. Emergency braking assistants should react appropriately to imminent dangers, even without human support, under consideration of tailgating cars and animals on the road. Modern image recognition or night vision systems can differentiate between animals and humans even in the dark; in conjunction with emergency braking assistants, they are capable of sound and right judgement. Generally, autonomous cars have to respond adequately to potential threats or accidents and escalate toward the human. Decision trees for autonomous cars and advanced driver assistance systems can look back on a certain tradition. Kopf, for instance, describes a simulative analysis with decision trees for assisting drivers on highways [23]. Lorenz too describes the instrument in the context of ADAS concepts and emphasizes that decision trees illustrate hierarchically staggered successions of decisions for classifying certain objects or conditions [24]. An annotated decision tree for actual implementation was proposed in [18].Autonomous cars are systems as versatile as drones. Driving is one of their core activities. To this end, many subtasks have to be mastered, including speed regulation, lane keeping and lane changing. The explanations below, created in the context of the ROBOCAR design study [18], are limited to braking. The modelling for ROBOCAR starts from the activity of driving (see Figure 2). The system checks whether there is an object on the road within a distance of less than 40 meters. If a human is in sight, an emergency or danger braking will be triggered. If an animal is in danger, the proceeding is similar as with the drone, depending on the type of animal. Collisions with bigger animals shall be avoided; rare species shall be considered and protected. Insects are exempt as braking for them would be uneconomical, and mobility, the object and purpose of driving, would be limited strongly. If the object is not a living creature, other potential facts will be considered [18]. Braking is required for bigger things, otherwise the vehicle could be damaged, and the lives of the passengers endangered. Before slowing down for things and animals alike it has to be checked whether another automobile is following behind the car. Some recent Mercedes-Benz models are furnished with a system capable of distinguishing between humans and animals, and intervening accordingly [18]. According to the Audi manufacturer’s technical specifications on the website (www.audi-mediacenter.com), the newer Audis differentiate between animals of different sizes. At least, this considers operative and probably also economic aspects, and is not far from ethical issues. The systems could benefit from the idea of an annotated decision tree. A current project investigates how to involve humans and animals in the system of highly and fully automated driving by electronification [25]. Many farm and domestic animals already wear data chips, or radio-frequency identification (RFID) chips, in or on them. If the RFID chips had a wide operating range, they could be used for identifying traffic participants. Some wild animals also have chips in their bodies, especially certain species or individuals in need of surveillance. An annotated decision tree would lso be interesting in this project, as some questions at the nodes could be answered better by data contained in the chips.

The LADYBIRD project

In 2014, the LADYBIRD design study provided a rough idea about the desired look and the planned functions of the device, and was published on the website www.maschinenethik.net and in [16]. The idea of the animal-friendly robot vacuum cleaner was mentioned in lectures, publications and interviews. On the one hand, it was well received by listeners and readers; on the other hand, it attracted the attention of the media and the interest of science [26]. Modern robot vacuum cleaners have a whole range of technologies and sensors, and the trend is towards less support and fewer accompanying measures. As much as possible, the goal is to enable them to act more and more autonomously. Barricades and crash barriers are often no longer needed, obstacles of all kinds are detected, and some hoovers return to their charging stations without any help. Ambitious devices scan the rooms in 3D, so that each area will be vacuumed. Also a linking with a user’s smartphone is possible, so he or she can give a command to clean or check the operability while out of the house. Cameras and ultrasonic sensors are more or less standard. In some newer models, infrared LED are incorporated for a better visibility in the dark [26]. In order to recognize a ladybird or ladybug, the robot vacuum cleaner will need sensory and analytical methods. Firstly, the device may try to detect, by means of color sensors, the red, reddish or yellowish color of the animals. Digital color measurement systems clearly distinguish between red, yellow, green and blue according to the reflection spectrum [27]. Secondly, the typical pattern, the 2 – 8 points on both wings, can be analyzed by a system with pattern recognition. The distances and the size of the points will be measured, if possible. Thirdly, using image recognition, the whole animal or the animal species can be identified. In this area several apps like “Map of Life” (mol.org) or “Project Noah” (www.projectnoah.org) already exist. Last but not least, motion detectors of several kinds can be included. A vacuuming robot’s main task is clearly defined: dealing with the vacuuming, the removal of debris and remains on the floor [2]. As it has been shown, other activities are interesting, in particular with respect to navigation and control. There are also approaches to employ the robot vacuum cleaner for the monitoring of the living quarters; via smartphone a user can access the integrated camera and align the device in a targeted way. In the following the author is focusing on suction. The starting point in the modelling – again an annotated decision tree (see Figure 3) – is the suction activity [2, 26]. It is checked whether there is something in the path of the vacuuming robot. If there is something in the way, and it is an animal, the vacuuming robot clarifies what size it is. Given the size of the suction equipment, a dog is not a problem. A ladybird or a caterpillar, however, is. The moral assumptions are rough and simple. They do not need to be shared by everybody. In fact, this is not even necessary since different devices are available. When a customer is purchasing a device, the extensions and restrictions, the product information, labels and certificates can be pointed out to her or to him, and she or he can be offered to have the machine modified according to her or his needs. Some people use the vacuum cleaner to suck in spiders or flies. They could be helped by LADYBIRD since it makes an exception for these insects. However, this contradicts the animal-friendly approach, and it must be discussed in principle whether such a possibility should be offered. If it is not a living being, other possible factors are included in the modelling. In 2017, three business information systems students of the School of Business FHNW implemented LADYBIRD as a prototype. They were able to show that the annotated decision tree was generally suitable for implementation. It was possible to translate it into Java (it has only been partially used). The students reached the limit with the technical requirements in the field of sensor technology. In the time available, it was not possible to consider pattern and image recognition or motion detectors. They nevertheless decided to focus on ladybirds. The recognition should not refer to the pattern, but to the color. The prototype is not round (as in the design study) but square, drives around on four wheels, recognizes obstacles with the help of an ultrasonic sensor, and changes direction upon detection of obstacles. By means of a color sensor it recognizes red zones on the ground. It scans the area it wants to drive on and it is able to “look” 10 centimeters ahead. If it detects a red spot or a red object, it ceases its work and gives out a signal to inform the owner [28]. It can also text the owner and he or she will receive the message even if not at home. In this case, the owner would have to restart the LADYBIRD (automatic restart after a certain time would be feasible and sensible). An alarm can be annoying for the user. He or she could also do without it and trust the machine, which would (as a product) usually continue to work once the animal has disappeared. A follow-up project in 2019 shall create a prototype coming even closer to the original vision. If possible, the entire annotated decision tree should be implemented, and other insects should also be considered. Pattern and image recognition must be part of the application. Ahead of the project start responsible persons, as well as students of the university, have to be made aware that the implementation of even simple moral machines requires broad technological skills.

Discussion of results

Decision trees are suitable for representing the moral decisions of simple moral machines. In projects at the School of Business FHNW they were modelled for the mentioned systems (and tasks). The moral assumptions or reasons were given in the annotations. The issue was not whether they were particularly cogent or shared by a great majority. It was more about principle. It was shown that other than moral justifications, reasons based on profit and operation, especially operational safety, are also relevant and sensible. The three concepts or projects already give an idea about the great variety of different cases and fields of application for machine ethics. LADYBIRD moves in apartments or houses, environments that are more or less closed and easy to oversee. It protects the lives of wild animals, namely insects, and can be implemented in a way that is considerate towards domestic animals (even if these are not endangered thanks to their size). An animal-friendly car can help protect wild animals as well as farm and domestic animals. It moves through open environments and is bound to the ground. The camera drone is considerate towards animals of all species. Wild animals especially, rarely used to humans and machines, can benefit from this system. It moves through open worlds and is air-bound, while a crash or landing also involves the ground. Several examples have been mentioned to show that semi-autonomous and autonomous systems can be made animal-friendly, which is of interest not only to animal welfare activists but also to car and machine engineering companies. With LADYBIRD in mind one could object that wild animals have no right to be in our homes, but on the other hand, hardly anyone of us would want to kill, or have killed (non-invasive) animals like ladybirds; and anyhow, the issue was to illustrate the principle. With regard to road traffic, of course car manufacturers do not prioritize animal rights. They rather focus on operative reliability and operative safety (for the occupants of the vehicle). However, it was shown that annotated decision trees are actually capable of working with several assumptions and justifications in parallel. There is a true need as the (mainly useless) road signs indicating hedgehog populations and toad migrations show. Camera drones could play a bigger and bigger role in the surveillance of landscapes (also with a view to monitoring forest fires). Animal-friendly behavior seems to be elementary. The examples focused on simple moral machines [2]. The moral decisions and behaviors are normally easily predictable and implementable, in closed space as well as in semi-open or open space. Different from where humans are concerned, quantifying (counting numbers) and qualifying (evaluating age, gender, origin, etc.) is not a problem when animal lives can be saved in the end. The ROBOCAR study is taking matters particularly far as it considers health and rarity of individuals. The technology partly is highly challenging and a task for the future. The LADYBIRD project has proven that the concerns of machine ethics should not be underestimated in terms of technology. Still closer cooperation between philosophers, computer scientists, and roboticists is needed to drive matters forward. The USA has already realized such cooperation: it has been shown in the conferences and publications [6], as well as countries such as the Netherlands, Portugal, Switzerland, Austria or Germany, while other parts of Europe, where there are few representatives of machine ethics, have not. Information and enlightenment within universities, among universities, and beyond universities is also helpful. The same project indicated that the moral assumptions and reasons have passed from the focus of attention over time, or have been transformed into technological processes, and can no longer be recognized as such. At least the signal to the user is a reminder and request. It reminds the user that LADYBIRD has a moral purpose and requests him or her to reactivate the machine. Once the machine restarts work without user input, which seems sensible for other reasons, this would be redundant. It has been proposed to furnish simple moral machines with a visible menu through which to control the morality of the machine. The owner of the machine could preset the machine to spare ladybirds but vacuum other, invasive or undesirable species. That may not sound very animal-friendly, but moral rules need not be enforced throughout when other requirements, such as a verminfree house, are justified. Nevertheless, it is important that the basic direction of the moral machine is respected and that it is not transformed into an immoral machine by the user. As was shown, machine ethics is not the only relevant discipline. It has to confer with human-machine interaction, animal-computer interaction and animal-machine interaction, if one can be established, with robotics and computer science. Both have to be sensitized to animal protection. Representatives of animal ethics have to be alerted to the developments in robotics and AI, and should be involved in both.

Possible other projects

Some possible applications will be identified below backed by this discussion [29], and in the tradition of the presented projects. This is based on two premises: (a) that machine ethics can and should contribute to the preliminary considerations and implementations and (b) that annotated decision trees can at least contribute. The focus is on service robots [30]: 1. Self-driving cars recognize animals of all species and brake for them, not only for reasons of operative safety, personal safety, or economy, but also for ethical reasons. In Australia, Volvo cars find kangaroos difficult to identify [31]. Problems of this kind should be solved. In response, a “kangaroo algorithm” could be developed and implemented. 2. Autonomous shuttles and trolleys recognize animals on real or virtual tracks and on the lane, and will brake under certain conditions, i.e., if it is a bigger animal, and if no passengers, or only seated passengers, are on board. If standing passengers could be hurt by braking, then braking has to be avoided. The known projects (like SmartShuttle in Sion) do not yet address this challenge. 3. Harvesters stop working once they discover a fawn in the field, not only for moral reasons, but also because of their operation. The first prototypes are already available, designed for instance by the German Aerospace Center (DLR). A drone flies ahead of the harvester and messages it as soon as it detects a fawn [32]. 4. Weeding robots do not spray their pesticides on animals like insects and small mammals, or are considerate and careful when weeding. Presently, the focus is mainly on plant health [33]. The focus could be expanded accordingly. 5. Wind power stations cease their work when flocks of birds or bats approach them. The first prototypes are already available [34]. One problem is that it takes long for the rotor to reach standstill, so the rescue operation might not be fast enough. The solution here lies not in better modeling, but in faster chips and better mechanics. 6. Surveillance and security robots stop in front of dogs or cats, trying to scare them away to keep them from harm. K5 and other robots are underway in shopping malls and on company grounds. Already a collision with a child has been reported [30]. Leashed animals especially might be in danger from these robots. 7. Package and transport robots stop in front of dogs and cats, and try to scare crows away to keep them from harm. Transport robots from Starship Technologies are being tested in Hamburg und Bern [30]. They are the same size as small dogs, and can get in conflict with all kinds of animals if they are considered intruders, and they might be attacked with teeth and claws. 8. Information and navigation robots instruct people in correct behavior towards animals, for instance in zoos or wildlife parks, and watch out for people coming too close or for children who want to feed the animals. Upon such detection, they report to a service, or appeal to the people. 9. Toy and entertainment robots recognize birds and bats entering a house, and report to the residents via signal or text. They behave appropriately towards domestic animals, for instance they respect when an animal has withdrawn, or has a favorite spot. They also function as toys for dogs or cats and can give them a workout. Of course there are other, different ways of thinking. Robots and autonomous machines can not only brake or cease their work for animals, spare them in a certain way, or scare them away to keep them from harm, or protect them; they can also actively approach them, to help them when they are sick or hurt, or to feed them, and the like. Some of these potential options have been illustrated with the representation of animal-machine interactions. Some fields of application, especially closed and semiopen environments, would probably benefit from selflearning systems capable of adjusting to the behavior of animals, and correcting and optimizing their behavior to fit the situation. They might also be purposive in open environments as with shuttles or trolleys driving on virtual or real tracks, but this can be problematic when many complex situations have to be analyzed and assessed. The kangaroo example shows a problem for animalfriendly machines which may arise in exceptional cases. When one uses decision trees, one maps a concrete, local reality in these. The machine will work well in this context. If you export it to another continent, it may fail, it may not react at all or it may make the wrong decisions. Other rigid procedures also have this deficit. One solution could be machine learning. The car could learn to deal with kangaroos over time. But machine learning raises many other questions. Depending on the algorithms and the environment, the car could learn something wrong. It is precisely this discussion that is basically being held with regard to autonomous cars. Some prefer shuttles that use maps and travel on fixed routes; others prefer cars that use artificial intelligence and machine learning to find their way around in any environment.

Summary and outlook

The young discipline of machine ethics can contribute to promote animal well-being, or reduce or avoid animal suffering. So far, this mostly has not been in the focus, at least not in the USA where the discipline has its biggest community. Three concepts for autonomous machines have been presented, and one of them has been implemented in prototype status. Annotated decision trees were used in all cases. Over the next years, many different service robots will become active in households, gardens and parks, on business sites, on roads and squares, on the ground and in the air. The issue is to make them all safe, not only for humans, but for animals as well. Machine ethics can provide a valuable contribution, and make sure the morality of machines considers animals. The presented decision trees or other approaches can be applied. In another step, more projects should be identified and prioritized. More models and prototypes can be created. It would be interesting to have a framework for the design of animal-friendly moral machines, based on a consolidation and comparison of the existing requirements and merging the annotated decision trees or specific algorithms on a meta level. Another important task is to clarify the roles and contributions of the different disciplines.